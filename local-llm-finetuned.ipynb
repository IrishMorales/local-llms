{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4fc0c4-5936-4eb3-9758-b1e6d1499c1b",
   "metadata": {},
   "source": [
    "# Finetuning a local LLM to autograde student essays\n",
    "\n",
    "This notebook downloads pretrained GPT-2, runs the model locally, and finetunes the model on mock data for essay autograding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23993a2-cc26-4aab-91c8-a091a42849e0",
   "metadata": {},
   "source": [
    "### Download and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a10d2c-b60b-4848-89f1-26a419f5a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.43.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\filelock-3.13.1-py3.11.egg (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\fsspec-2023.10.0-py3.11.egg (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\filelock-3.13.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\fsspec-2023.10.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\mpmath-1.3.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\pygcn-0.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\sympy-1.12-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\Irish\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.43.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\filelock-3.13.1-py3.11.egg (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.33.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\fsspec-2023.10.0-py3.11.egg (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\sympy-1.12-py3.11.egg (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\mpmath-1.3.0-py3.11.egg (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\filelock-3.13.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\fsspec-2023.10.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\mpmath-1.3.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\pygcn-0.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\users\\irish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\sympy-1.12-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\Irish\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Download libraries\n",
    "%pip install transformers\n",
    "%pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6955e695-518e-4943-bcf0-bafd03f8e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed libraries\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b2af6-fefa-4b14-bca1-cfbd94a89a3b",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14173caa-24f7-493a-896b-28293531fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained LLM and tokenizer\n",
    "model_name = \"gpt2\" # Replace with name of the LLM you want to run\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee21bfd0-32f5-4828-877d-c1fc128850e1",
   "metadata": {},
   "source": [
    "### Choose device for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954934ec-7a9b-49cc-ad2a-47f9b164e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device to run the model (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38605b-895f-4e4a-8e39-6d556d2fe304",
   "metadata": {},
   "source": [
    "### Create dataset for finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb356ad-c4f2-4c80-819e-1b839e88c9dc",
   "metadata": {},
   "source": [
    "This generates mock data for a dataset of essays on which to fine-tune a local model based on the [ASAP dataset](https://www.kaggle.com/competitions/asap-aes/rules). Essays are generated with Google Gemini, and essay scores/targets are manually graded according to the ASAP dataset rubrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eec1132-0211-4649-aa00-8aacc632a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['essay_set', 'essay', 'ground_truth_score']\n",
    "data = [\n",
    "    [\n",
    "        1,\n",
    "        \"Is everyone freaking out about computers for no reason? Computers are awesome! They're like having a superhero sidekick in your pocket. They can teach you anything you want to know, from how to build a volcano (for science class, of course!) to what life is like on the other side of the world. Plus, games help your hand-eye coordination, which is basically a superpower for gamers like me.\\n\\nSure, maybe some grown-ups spend too much time staring at screens, but that's their problem, not ours. We can totally use computers for good stuff and still hang out with friends or play outside.  So, lighten up everyone, computers are here to stay, and they're making our lives way cooler!\\n\\nYour friend,\\n\\nGamer Girl extraordinaire\",\n",
    "        2\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nComputers are like a double-edged sword. On one hand, they're amazing tools for learning and connecting. I can chat with my cousin in California even though she's miles away, and research projects are a breeze with all the information online. Plus, there are these awesome educational games that make learning history or even another language actually fun!\\n\\nBut on the other hand, sometimes computers can be a total time suck. You start checking one thing, and then BAM! Two hours later, you're watching cat videos (don't judge, they're hilarious!).  This can lead to neglecting real-life stuff like hanging out with friends or getting enough exercise.\\n\\nSo, I think the key is balance. Computers are great, but we gotta make sure they don't take over our lives. Maybe parents can set screen time limits, and we can all make a conscious effort to spend more time outside and with loved ones.\\n\\nSincerely,\\n\\nA Balanced Computer User\",\n",
    "        4\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nSome people say computers are turning us all into couch potatoes. They might have a point. It's way easier to watch funny videos online than go for a bike ride.  But computers can actually help you appreciate nature too! You can research cool animals or amazing places you want to visit someday.  Plus, there are apps that help you identify plants and track your hikes.\\n\\nThink of it like this: computers are like a superhighway to information, but sometimes you gotta take an exit and explore the real world. We can use computers to learn about nature, then go outside and experience it for ourselves. It's all about finding the right balance!\\n\\nYours truly,\\n\\nThe Tech-Savvy Nature Enthusiast\",\n",
    "        3\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nComputers aren't just about games and social media, you know! They can be a real spark for creativity.  I can write stories on the computer, way easier than using pen and paper. Plus, there are these amazing programs that let you design animations or even create your own music!  Imagine composing a song as cool as your favourite band, all on your computer.\\n\\nSure, some folks might say computers make us lazy, but I think they actually help us think outside the box. You can find inspiration for anything online, from historical fashion to crazy science experiments.  Computers are like a giant toolbox full of cool stuff to help you express yourself.\\n\\nSo next time someone tells you to get off the computer, tell them you're busy building your own creativity empire!\\n\\nYours creatively,\\n\\nThe Techie Da Vinci\",\n",
    "        4\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nLet's be honest, computers can be way better friends than some actual people. They're always there, 24/7, whenever you need them. Feeling bored? Boom, there's a million games to play. Need help with homework? Online resources can explain anything. Plus, you can connect with people who share your interests, no matter how weird or wonderful they are.\\n\\nOf course, computers can't replace real-life friends entirely. But they can be a great way to meet new people, especially if you're shy or new to town.  Think of them as awesome companions who can help you learn, play, and connect with the world.\\n\\nYour friend (both online and off),\\n\\nThe Social Butterfly with a Keyboard\",\n",
    "        3\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nFor history buffs like me, computers are a dream come true!  Imagine having access to museums and libraries from all over the world, all at your fingertips. You can explore ancient civilizations, watch historical battles come to life in documentaries, or even take virtual tours of famous landmarks.\\n\\nTextbooks are cool, but computers let you experience history in a whole new way. You can see real photos and videos, listen to speeches from famous people, and even read primary source documents.  It's like stepping right back in time, without needing a time machine (although that would be pretty awesome too!).\\n\\nSo next time you hear someone complaining about computers, tell them about the history buff's paradise they're missing out on!\\n\\nSincerely,\\n\\nThe Time-Traveling Student (via Computer)\",\n",
    "        3\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nThe conversation about computers seems stuck in a binary – productivity boosters or social isolation machines. While I agree computers offer undeniable benefits – research efficiency, global communication, and even entertainment – I believe their impact on productivity might be a double-edged sword.\\n\\nOn the surface, computers streamline tasks, from research to collaboration. Gone are the days of scouring libraries; now, a quick keyword search yields mountains of information. However, this very convenience can be a productivity trap. The endless stream of notifications, social media updates, and the allure of online entertainment can easily derail focus.\\n\\nFurthermore, the multitasking culture computers foster might be an illusion. Studies suggest rapid switching between tasks actually diminishes efficiency. The constant barrage of stimuli creates a fear of missing out mentality, leading us to flit between tasks, achieving none in depth.\\n\\nSo, how do we utilize the benefits of computers without succumbing to their productivity paradox? Perhaps a conscious effort towards focused work sessions, utilizing time management tools, and even strategically disconnecting from the digital world could be the answer.\\n\\nComputers are powerful tools, but ultimately, it's up to us to harness their potential for true productivity, not get lost in the digital whirlwind.\\n\\nSincerely,\\n\\nA Student in the Age of Distraction\",\n",
    "        5\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nThe internet age, ushered in by computers, has undeniably expanded our access to information and connection. However, I believe the rise of \\\"echo chambers\\\" on social media platforms presents a significant threat to critical thinking and genuine discourse.\\n\\nComputers have created personalized online experiences. News feeds curate content based on our preferences, surrounding us with information that confirms our existing beliefs. This insular environment fosters confirmation bias, where we dismiss opposing viewpoints and cling to opinions that resonate with our own.\\n\\nThis lack of exposure to diverse perspectives hinders intellectual growth and stifles healthy debate.  Civil discourse necessitates grappling with opposing views, challenging our assumptions, and fostering empathy. Echo chambers, on the other hand, create intellectual bubbles, leading to polarization and a decline in open-mindedness.\\n\\nTo counteract these effects, we must consciously seek out diverse viewpoints on computers themselves. We can utilize search engines to find information from various sources and engage in respectful online discussions with those who hold differing opinions.\\n\\nComputers are powerful tools for connection, but they shouldn't limit our intellectual horizons.  Let's harness their potential to create a more informed and intellectually diverse society.\\n\\nSincerely,\\n\\nA Student Who Values Open Discourse\",\n",
    "        5\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nThe internet, facilitated by computers, has democratized access to information and ignited a wave of social activism. However, the ease of online engagement might be creating a culture of \\\"clicktivism\\\" – shallow, performative activism that prioritizes social media validation over meaningful action.\\n\\nComputers allow us to instantly share petitions, raise awareness for causes, and connect with like-minded individuals. However, this ease of engagement can lead to a sense of accomplishment without actual effort. Signing a petition online might feel good, but it doesn't translate to real-world change unless followed by concrete action.\\n\\nFurthermore, the curated nature of social media feeds can create a skewed perception of reality. We might be bombarded with success stories, fostering a sense of discouragement when our own efforts seem insignificant. This can lead to slacktivism, where individuals feel absolved of their responsibility after a simple click.\\n\\nComputers can be powerful tools for social change, but we must guard against mistaking online engagement for genuine activism. It's crucial to translate our digital outrage into concrete action, volunteering, and creating a dialogue with those who hold opposing views.  Only then can we  leverage the power of computers to create lasting social change.\\n\\nSincerely,\\n\\nA Student Who Believes in Action, Not Just Likes\",\n",
    "        5\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nComputers are like double-stuffed Oreos: awesome and delicious, but you gotta be careful not to overdo it. Sure, they can be educational – research projects are a breeze with all that info online, and some games are actually pretty challenging (think reflexes of a ninja!). Plus, you can video chat with your bestie across town, way cooler than a boring phone call.\\n\\nBut let's face it, computers can be a major time suck. You hop on to check something quick, and next thing you know, hours have flown by scrolling through social media or watching random videos.  Suddenly, you haven't gotten any homework done, and your mom's nagging you to get outside.\\n\\nThe key is balance, people! Computers are great tools, but they shouldn't replace real life. We need to get our exercise, spend time with friends and fam, and maybe even appreciate some fresh air (believe it or not, the world outside your screen is pretty cool too!). So, let's use computers to our advantage, but remember, there's a whole world out there waiting to be explored –  the non-digital kind!\\n\\nSincerely,\\n\\nThe Tech-Savvy (But Not Screen-Obsessed) Teenager\",\n",
    "        3\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nLook, I get it. Some adults think computers are turning us all into antisocial code monkeys. They whine about us glued to screens, neglecting exercise and real-life interactions. But here's the thing: computers can actually be social tools!\\n\\nThink about it. We can connect with friends online, share jokes and stories, even play games together virtually. Plus, social media lets you meet new people who share your interests, no matter how niche they are. It's like having a giant club for everything under the sun, all online!\\n\\nSure, computers shouldn't replace face-to-face interactions. But honestly, some people are just way more comfortable expressing themselves online. Plus, there are plenty of introverts and shy kids out there who benefit from the social connection computers offer.\\n\\nSo, next time you see a teenager staring at a screen, don't assume the worst. We might be having the best virtual hangout ever, making new friends, or even learning a new skill. Computers can be social butterflies too!\\n\\nYours truly,\\n\\nThe Socially Connected Screenager\",\n",
    "        3\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nComputers aren't just a trend, they're the future! They're changing the world, and it's not all doom and gloom like some grumpy grown-ups think.  Learning? Computers make it interactive and fun. Need to connect with someone across the globe? Done in seconds.  Plus, with online courses and coding programs, teenagers like me can actually learn future-proof skills.\\n\\nSure, too much screen time can be bad, but guess what? We're smart enough to find a balance.  We can use computers to learn about fitness and healthy habits. Plus, there are apps for tracking hikes and even virtual reality experiences that take you to exotic locations.\\n\\nHonestly, computers are opening doors to a whole new world. We can be part of the solution, not the problem. Let's embrace technology and use it to our advantage. The future is digital, and  guess what? We're ready for it!\\n\\nSincerely,\\n\\nThe Tech-Ready Teenager\",\n",
    "        3\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nThe rise of computers has sparked a heated debate – are they a boon or a bane for society? While some laud their educational and social advantages, concerns about human connection and physical well-being loom large.\\n\\nUndeniably, computers offer unparalleled access to information. From research for academic papers to virtual tours of the Colosseum, knowledge is democratized. Additionally, online platforms foster social connection – video calls bridge geographical distances, and online communities allow people with shared interests to connect.\\n\\nHowever, these benefits come at a cost. The allure of the digital world can foster social isolation. Face-to-face interactions, crucial for emotional well-being and developing social skills, can be neglected. Furthermore, the sedentary nature of computer use contributes to a decline in physical activity, leading to health problems.\\n\\nThe solution lies not in abandoning technology, but in cultivating a mindful relationship with it. We must prioritize real-world interactions and physical activities. Setting time limits for computer use and scheduling outdoor adventures are essential.\\n\\nUltimately, computers are tools – powerful and transformative, but ultimately neutral. It is up to us to harness their potential while remaining grounded in the real world. Let us not become slaves to technology, but rather its responsible stewards.\\n\\nSincerely,\\n\\nA Concerned Citizen of the Digital Age\",\n",
    "        5\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nThe pervasiveness of computers in our lives presents a double-edged sword – a vast ocean of information at our fingertips, coupled with the potential for intellectual stagnation. While proponents highlight the educational advantages of computers, the ease of access can breed a culture of passive information consumption.\\n\\nUndoubtedly, computers are gateways to knowledge. Research for projects becomes a breeze, and online courses offer unprecedented educational opportunities. Additionally, global news platforms allow us to stay informed about international affairs.\\n\\nHowever, the sheer volume of information available online can be overwhelming. The ability to discern credible sources from fake news is crucial, yet neglected. Furthermore, the reliance on pre-summarized information can hinder the development of critical thinking skills.\\n\\nTo mitigate these risks, we need to foster an environment that encourages active information processing. Evaluating sources, questioning assumptions, and drawing reasoned conclusions are paramount. Additionally, we must advocate for educational reforms that emphasize critical thinking alongside access to information.\\n\\nIn conclusion, computers can be powerful tools for learning, but only if we cultivate the skills to navigate the information landscape effectively. Let us not become passive consumers of data, but rather discerning learners who utilize technology to expand our intellectual horizons.\\n\\nSincerely,\\n\\nA Student of the Digital Age\",\n",
    "        5\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nThe rise of computers has coincided with a growing concern - the erosion of privacy in the digital age. While proponents highlight the social and educational benefits of computers, the trade-off is often our personal data becoming a valuable commodity for corporations.\\n\\nUndeniably, computers facilitate social interactions and educational pursuits. Online platforms connect us with loved ones across the globe, and online courses offer flexible learning opportunities.\\n\\nHowever, our online activities generate a vast trail of data – search history, social media interactions, even location tracking. This data is often collected and monetized by corporations, potentially leading to targeted advertising and even manipulation.\\n\\nThe solution lies in advocating for stricter data protection laws and fostering a culture of digital hygiene. We must be vigilant about the information we share online and utilize tools to protect our privacy. Additionally, promoting digital literacy is crucial to empower individuals to navigate the complexities of online data collection.\\n\\nIn conclusion, computers offer undeniable benefits, but at a cost – our privacy. Striking a balance between technological advancement and individual autonomy is paramount. Let us reclaim control over our digital footprints and ensure that computers are tools for empowerment, not instruments of surveillance.\\n\\nSincerely,\\n\\nA Concerned Citizen of the Digital Age\",\n",
    "        5\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nSome grown-ups might moan about computers turning our brains to mush, but they're totally wrong! Computers are like a giant learning playground, way cooler than dusty old textbooks. Wanna learn about the pyramids? Boom, there's a virtual tour online. Need help with a science project? There are tons of websites with experiments you can actually do at home (with adult supervision, of course!).\\n\\nPlus, forget boring lectures – some online courses have games and quizzes that make learning actually fun! And don't even get me started on coding. It's like learning a secret language that lets you build your own computer games!\\n\\nSure, sometimes you can get sucked into a black hole of cat videos, but that's why we need balance. Maybe parents can set screen time limits, and we can all make an effort to play outside more. But honestly, computers are here to stay, and they're making learning way more awesome!\\n\\nYour fellow student,\\n\\nThe Tech-Savvy Brainiac\",\n",
    "        3\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nComputers are awesome for some things, but they can also be a bit of a double-edged sword, especially when it comes to friends. On the one hand, they let you connect with people from all over the world, which is pretty cool. You can video chat with your cousin in Hawaii or chat with someone who shares your love for obscure cartoon characters.\\n\\nBut here's the thing: computers can't replace real-life friends. Sure, you can text your bestie all day, but there's nothing like hanging out in person, cracking jokes, and maybe even getting into a friendly game of dodgeball.\\n\\nSometimes, computers can make us forget about the people right next to us. We get so caught up in the online world that we forget to spend quality time with our family or even just play with the dog.\\n\\nSo, the key is balance. Let's use computers to connect with people far away, but don't forget to nurture the friendships we have in real life too. Remember, a computer friend can't give you a high five!\\n\\nSincerely,\\n\\nThe Socially Balanced Student\",\n",
    "        4\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nSome folks think computers are turning us into couch potatoes, glued to screens and forgetting about the great outdoors. They might have a point – who needs a walk in the park when you can explore a rainforest virtually?\\n\\nBut here's the secret: computers can actually help you appreciate nature even more! You can research cool animals you want to see someday, like majestic tigers or playful dolphins. Plus, there are apps that help you identify plants and track your hikes. Imagine hiking a mountain and using an app to learn all about the different trees you see!\\n\\nThink of computers as an escape hatch from the everyday. They can transport you to amazing places, but they can also inspire you to experience the real thing. So next time you're feeling cooped up, use your computer to plan an awesome outdoor adventure, not just another virtual one!\\n\\nYours truly,\\n\\nThe Tech-Powered Nature Enthusiast\",\n",
    "        4\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nThe rise of computers has fundamentally reshaped the landscape of knowledge acquisition. While concerns about attention spans and social isolation are valid, the democratization of information access outweighs these anxieties.\\n\\nPrior to the digital age, knowledge was largely siloed within academic institutions and specialized libraries. Today, computers provide unprecedented access to a vast ocean of information. Online databases, academic journals, and educational platforms empower individuals to pursue intellectual curiosity regardless of geographic location or socioeconomic background.\\n\\nHowever, the sheer volume of information can be overwhelming. Critical thinking skills are paramount in navigating the digital terrain, discerning credible sources from misinformation. Universities and educators must adapt, fostering information literacy alongside access.\\n\\nFurthermore, the always-on nature of technology can lead to social isolation and hinder physical well-being.  Encouraging digital  detoxification and promoting healthy screen time habits are crucial. Yet, the ability to connect with colleagues and friends globally fosters a sense of global citizenship and facilitates collaboration across borders.\\n\\nIn conclusion, the democratizing potential of computers outweighs concerns about their downsides. By fostering critical thinking skills and promoting balance in our digital lives, we can harness the power of technology to empower individuals and advance human knowledge.\\n\\nSincerely,\\n\\n\",\n",
    "        5\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"Dear Editor,\\n\\nWhile computers hold immense potential for learning and connection, they can exacerbate existing societal inequalities.  While proponents tout the democratization of information, the reality is a widening algorithmic divide.\\n\\nUnequal access to computers and reliable internet connections limits opportunities for those in underserved communities.  Without this access, educational pursuits, professional development, and even basic communication are hindered.   Furthermore, the digital divide disproportionately affects marginalized groups, further perpetuating social and economic disparities.\\n\\nMoreover, the internet thrives on data, leading to algorithmic biases.  Search engines and social media platforms often prioritize content that confirms existing beliefs, creating echo chambers that hinder exposure to diverse viewpoints and critical thinking.\\n\\nTo mitigate these issues, we need robust investment in public libraries, affordable internet access programs, and digital literacy initiatives. Additionally, platforms need to be held accountable for algorithmic bias, ensuring inclusive and equitable information access.\\n\\nIn conclusion, the benefits of computers cannot be fully realized without addressing the digital divide and algorithmic bias.  Otherwise, these technological advancements will only exacerbate existing inequalities.  Let us bridge this gap and ensure that computers empower all individuals, not just a privileged few.\\n\\nSincerely,\\n\\nA Social Scientist of the Digital Age\",\n",
    "        5\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb02dca2-8572-4f05-9072-b8a256128f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate essay IDs\n",
    "start_id = 7085\n",
    "essay_df = pd.DataFrame(data=data, columns=columns)\n",
    "essay_df['essay_id'] = np.arange(start_id, start_id + len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df85d35-625d-4a58-9e19-d6493d5a9792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>ground_truth_score</th>\n",
       "      <th>essay_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Is everyone freaking out about computers for n...</td>\n",
       "      <td>2</td>\n",
       "      <td>7085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Editor,\\n\\nComputers are like a double-ed...</td>\n",
       "      <td>4</td>\n",
       "      <td>7086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Editor,\\n\\nSome people say computers are ...</td>\n",
       "      <td>3</td>\n",
       "      <td>7087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Editor,\\n\\nComputers aren't just about ga...</td>\n",
       "      <td>4</td>\n",
       "      <td>7088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Editor,\\n\\nLet's be honest, computers can...</td>\n",
       "      <td>3</td>\n",
       "      <td>7089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                              essay  \\\n",
       "0          1  Is everyone freaking out about computers for n...   \n",
       "1          1  Dear Editor,\\n\\nComputers are like a double-ed...   \n",
       "2          1  Dear Editor,\\n\\nSome people say computers are ...   \n",
       "3          1  Dear Editor,\\n\\nComputers aren't just about ga...   \n",
       "4          1  Dear Editor,\\n\\nLet's be honest, computers can...   \n",
       "\n",
       "   ground_truth_score  essay_id  \n",
       "0                   2      7085  \n",
       "1                   4      7086  \n",
       "2                   3      7087  \n",
       "3                   4      7088  \n",
       "4                   3      7089  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7eaf83-ca80-4052-9ab5-b864fe064a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_df.to_csv('finetune_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "225f5b5a-41e0-4f58-8b5f-dddc0eaac397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, finetune_set_path, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        df = pd.read_csv(finetune_set_path)\n",
    "        self.inputs = df['essay']\n",
    "        self.labels = df['ground_truth_score']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.inputs.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encodings = self.tokenizer(input,\n",
    "                                   return_tensors='pt',\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=512)\n",
    "        return encodings.input_ids.squeeze(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b515e8c7-000c-42dc-89c9-80a4495b50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = EssayDataset('finetune_set.csv', tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012ae5fc-b66f-4cfe-bfbe-498df6d2e473",
   "metadata": {},
   "source": [
    "### Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a98368c6-92a9-412f-8ff0-2c4d5d8d2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61b95755-29af-4532-98ce-e16b5124478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch inputs\n",
    "def data_collator(features):\n",
    "    input_ids = torch.stack([f[0] for f in features])\n",
    "    labels = torch.tensor([f[1] for f in features])\n",
    "    labels = labels.view(-1, 1).expand_as(input_ids)\n",
    "    return {'input_ids': input_ids, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be352ad9-d3bb-4b37-8c42-f5233f1ae202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbc2ebf5-3e5c-4a46-b067-4667819bfa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3dfc9cb-10cc-416a-b707-1447c9b35aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 04:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.521059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.759300</td>\n",
       "      <td>12.057110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.264300</td>\n",
       "      <td>11.322369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=24, training_loss=11.439710776011148, metrics={'train_runtime': 274.8156, 'train_samples_per_second': 0.175, 'train_steps_per_second': 0.087, 'total_flos': 12542017536000.0, 'train_loss': 11.439710776011148, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ea1e7-8492-4774-a6d0-f65e8c8ff046",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af7fb153-275e-42a5-8013-86a5f60ef415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine-tuned-gpt2\\\\tokenizer_config.json',\n",
       " './fine-tuned-gpt2\\\\special_tokens_map.json',\n",
       " './fine-tuned-gpt2\\\\vocab.json',\n",
       " './fine-tuned-gpt2\\\\merges.txt',\n",
       " './fine-tuned-gpt2\\\\added_tokens.json',\n",
       " './fine-tuned-gpt2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('./fine-tuned-gpt2')\n",
    "tokenizer.save_pretrained('./fine-tuned-gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0000ca29-8beb-40d0-9674-f98042438e84",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4d1a7-3c58-490b-bf66-2de205adda12",
   "metadata": {},
   "source": [
    "## Automated Essay Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02aa807-cb95-400f-af90-7ab834959508",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98cb072b-dc9d-4b47-b2b1-a63b7386869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_df = pd.read_csv(\"data/training_set.tsv\", sep='\\t', encoding = \"ISO-8859-1\")\n",
    "essay_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395920e-24bf-4179-b932-446c88f6a388",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f6c538-6672-40e7-b16f-45f41c43f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused columns\n",
    "essay_df = essay_df.drop(['rater2_domain1', 'domain1_score', 'rater3_domain1', 'rater1_domain2', 'rater2_domain2', 'domain2_score',\n",
    "                          'rater1_trait1', 'rater1_trait2', 'rater1_trait3', 'rater1_trait4', 'rater1_trait5', 'rater1_trait6',\n",
    "                          'rater2_trait1', 'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5', 'rater2_trait6',\n",
    "                          'rater3_trait1', 'rater3_trait2', 'rater3_trait3', 'rater3_trait4', 'rater3_trait5', 'rater3_trait6'],\n",
    "                          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1948ab43-8fb3-4345-a1f7-1a1095049cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused essay sets\n",
    "essay_df = essay_df[essay_df.essay_set == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa3b0ae-cf73-458e-b2f0-fbddffa546e9",
   "metadata": {},
   "source": [
    "### Rubric Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e90b32e-c581-4dca-8037-81d931354d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>score_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>Score Point 1: An undeveloped response that ma...</td>\n",
       "      <td>1-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Source Essay: ROUGH ROAD AHEAD: Do Not Exceed ...</td>\n",
       "      <td>Score Point 3: The response demonstrates an un...</td>\n",
       "      <td>0-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Source Essay: Winter Hibiscus by Minfong Ho Sa...</td>\n",
       "      <td>Score Point 3: The response demonstrates an un...</td>\n",
       "      <td>0-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Source Essay: Narciso Rodriguez from Home: The...</td>\n",
       "      <td>Score Point 4: The response is a clear, comple...</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set  grade_level                                             prompt  \\\n",
       "0          1            8  More and more people use computers, but not ev...   \n",
       "1          3           10  Source Essay: ROUGH ROAD AHEAD: Do Not Exceed ...   \n",
       "2          4           10  Source Essay: Winter Hibiscus by Minfong Ho Sa...   \n",
       "3          5            8  Source Essay: Narciso Rodriguez from Home: The...   \n",
       "\n",
       "                                             rubrics score_range  \n",
       "0  Score Point 1: An undeveloped response that ma...         1-6  \n",
       "1  Score Point 3: The response demonstrates an un...         0-3  \n",
       "2  Score Point 3: The response demonstrates an un...         0-3  \n",
       "3  Score Point 4: The response is a clear, comple...         0-4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['essay_set', 'grade_level', 'prompt', 'rubrics', 'score_range']\n",
    "data = [\n",
    "    [\n",
    "        1,\n",
    "        8,\n",
    "        \"More and more people use computers, but not everyone agrees that this benefits society. Those who support advances in technology believe that computers have a positive effect on people. They teach hand-eye coordination, give people the ability to learn about faraway places and people, and even allow people to talk online with other people. Others have different ideas. Some experts are concerned that people are spending too much time on their computers and less time exercising, enjoying nature, and interacting with family and friends. Write a letter to your local newspaper in which you state your opinion on the effects computers have on people. Persuade the readers to agree with you.\",\n",
    "        \"Score Point 1: An undeveloped response that may take a position but offers no more than very minimal support. Typical elements: Contains few or vague details. Is awkward and fragmented. May be difficult to read and understand. May show no awareness of audience.\\nScore Point 2: An under-developed response that may or may not take a position. Typical elements: Contains only general reasons with unelaborated and/or list-like details. Shows little or no evidence of organization. May be awkward and confused or simplistic. May show little awareness of audience. \\nScore Point 3: A minimally-developed response that may take a position, but with inadequate support and details. Typical elements: Has reasons with minimal elaboration and more general than specific details. Shows some organization. May be awkward in parts with few transitions. Shows some awareness of audience. \\nScore Point 4: A somewhat-developed response that takes a position and provides adequate support. Typical elements: Has adequately elaborated reasons with a mix of general and specific details. Shows satisfactory organization. May be somewhat fluent with some transitional language. Shows adequate awareness of audience. \\nScore Point 5: A developed response that takes a clear position and provides reasonably persuasive support. Typical elements: Has moderately well elaborated reasons with mostly specific details. Exhibits generally strong organization. May be moderately fluent with transitional language throughout. May show a consistent awareness of audience. \\nScore Point 6: A well-developed response that takes a clear and thoughtful position and provides persuasive support. Typical elements: Has fully elaborated reasons with specific details. Exhibits strong organization. Is fluent and uses sophisticated transitional language. May show a heightened awareness of audience.\",\n",
    "        \"1-6\"\n",
    "    ],\n",
    "    [\n",
    "        3,\n",
    "        10,\n",
    "        \"Source Essay: ROUGH ROAD AHEAD: Do Not Exceed Posted Speed Limit by Joe Kurmaskie FORGET THAT OLD SAYING ABOUT NEVER taking candy from strangers. No, a better piece of advice for the solo cyclist would be, “Never accept travel advice from a collection of old-timers who haven’t left the confines of their porches since Carter was in office.” It’s not that a group of old guys doesn’t know the terrain. With age comes wisdom and all that, but the world is a fluid place. Things change. At a reservoir campground outside of Lodi, California, I enjoyed the serenity of an early-summer evening and some lively conversation with these old codgers. What I shouldn’t have done was let them have a peek at my map. Like a foolish youth, the next morning I followed their advice and launched out at first light along a “shortcut” that was to slice away hours from my ride to Yosemite National Park. They’d sounded so sure of themselves when pointing out landmarks and spouting off towns I would come to along this breezy jaunt. Things began well enough. I rode into the morning with strong legs and a smile on my face. About forty miles into the pedal, I arrived at the first “town.” This place might have been a thriving little spot at one time—say, before the last world war—but on that morning it fit the traditional definition of a ghost town. I chuckled, checked my water supply, and moved on. The sun was beginning to beat down, but I barely noticed it. The cool pines and rushing rivers of Yosemite had my name written all over them. Twenty miles up the road, I came to a fork of sorts. One ramshackle shed, several rusty pumps, and a corral that couldn’t hold in the lamest mule greeted me. This sight was troubling. I had been hitting my water bottles pretty regularly, and I was traveling through the high deserts of California in June. I got down on my hands and knees, working the handle of the rusted water pump with all my strength. A tarlike substance oozed out, followed by brackish water feeling somewhere in the neighborhood of two hundred degrees. I pumped that handle for several minutes, but the water wouldn’t cool down. It didn’t matter. When I tried a drop or two, it had the flavor of battery acid. The old guys had sworn the next town was only eighteen miles down the road. I could make that! I would conserve my water and go inward for an hour or so—a test of my inner spirit. Not two miles into this next section of the ride, I noticed the terrain changing. Flat road was replaced by short, rolling hills. After I had crested the first few of these, a large highway sign jumped out at me. It read: ROUGH ROAD AHEAD: DO NOT EXCEED POSTED SPEED LIMIT. The speed limit was 55 mph. I was doing a water-depleting 12 mph. Sometimes life can feel so cruel. I toiled on. At some point, tumbleweeds crossed my path and a ridiculously large snake—it really did look like a diamondback—blocked the majority of the pavement in front of me. I eased past, trying to keep my balance in my dehydrated state. The water bottles contained only a few tantalizing sips. Wide rings of dried sweat circled my shirt, and the growing realization that I could drop from heatstroke on a gorgeous day in June simply because I listened to some gentlemen who hadn’t been off their porch in decades, caused me to laugh. It was a sad, hopeless laugh, mind you, but at least I still had the energy to feel sorry for myself. There was no one in sight, not a building, car, or structure of any kind. I began breaking the ride down into distances I could see on the horizon, telling myself that if I could make it that far, I’d be fi ne. Over one long, crippling hill, a building came into view. I wiped the sweat from my eyes to make sure it wasn’t a mirage, and tried not to get too excited. With what I believed was my last burst of energy, I maneuvered down the hill. In an ironic twist that should please all sadists reading this, the building—abandoned years earlier, by the looks of it—had been a Welch’s Grape Juice factory and bottling plant. A sandblasted picture of a young boy pouring a refreshing glass of juice into his mouth could still be seen. I hung my head. That smoky blues tune “Summertime” rattled around in the dry honeycombs of my deteriorating brain. I got back on the bike, but not before I gathered up a few pebbles and stuck them in my mouth. I’d read once that sucking on stones helps take your mind off thirst by allowing what spit you have left to circulate. With any luck I’d hit a bump and lodge one in my throat. It didn’t really matter. I was going to die and the birds would pick me clean, leaving only some expensive outdoor gear and a diary with the last entry in praise of old men, their wisdom, and their keen sense of direction. I made a mental note to change that paragraph if it looked like I was going to lose consciousness for the last time. Somehow, I climbed away from the abandoned factory of juices and dreams, slowly gaining elevation while losing hope. Then, as easily as rounding a bend, my troubles, thirst, and fear were all behind me. GARY AND WILBER’S FISH CAMP—IF YOU WANT BAIT FOR THE BIG ONES, WE’RE YOUR BEST BET! “And the only bet,” I remember thinking. As I stumbled into a rather modern bathroom and drank deeply from the sink, I had an overwhelming urge to seek out Gary and Wilber, kiss them, and buy some bait—any bait, even though I didn’t own a rod or reel. An old guy sitting in a chair under some shade nodded in my direction. Cool water dripped from my head as I slumped against the wall beside him. “Where you headed in such a hurry?” “Yosemite,” I whispered. “Know the best way to get there?” I watched him from the corner of my eye for a long moment. He was even older than the group I’d listened to in Lodi. “Yes, sir! I own a very good map.” And I promised myself right then that I’d always stick to it in the future. “Rough Road Ahead” by Joe Kurmaskie, from Metal Cowboy, copyright © 1999 Joe Kurmaskie. Instructions: Write a response that explains how the features of the setting affect the cyclist. In your response, include examples from the essay that support your conclusion.\",\n",
    "        \"Score Point 3: The response demonstrates an understanding of the complexities of the text. Addresses the demands of the question Uses expressed and implied information from the text Clarifies and extends understanding beyond the literal \\nScore 2: The response demonstrates a partial or literal understanding of the text. Addresses the demands of the question, although may not develop all parts equally Uses some expressed or implied information from the text to demonstrate understanding May not fully connect the support to a conclusion or assertion made about the text(s) \\nScore 1: The response shows evidence of a minimal understanding of the text. May show evidence that some meaning has been derived from the text May indicate a misreading of the text or the question May lack information or explanation to support an understanding of the text in relation to the question \\nScore Point 0: The response is completely irrelevant or incorrect, or there is no response.\",\n",
    "        \"0-3\"\n",
    "    ],\n",
    "    [\n",
    "        4,\n",
    "        10,\n",
    "        'Source Essay: Winter Hibiscus by Minfong Ho Saeng, a teenage girl, and her family have moved to the United States from Vietnam. As Saeng walks home after failing her driver’s test, she sees a familiar plant. Later, she goes to a florist shop to see if the plant can be purchased. It was like walking into another world. A hot, moist world exploding with greenery. Huge flat leaves, delicate wisps of tendrils, ferns and fronds and vines of all shades and shapes grew in seemingly random profusion. “Over there, in the corner, the hibiscus. Is that what you mean?” The florist pointed at a leafy potted plant by the corner. There, in a shaft of the wan afternoon sunlight, was a single blood-red blossom, its five petals splayed back to reveal a long stamen tipped with yellow pollen. Saeng felt a shock of recognition so intense, it was almost visceral.1 “Saebba,” Saeng whispered. A saebba hedge, tall and lush, had surrounded their garden, its lush green leaves dotted with vermilion flowers. And sometimes after a monsoon rain, a blossom or two would have blown into the well, so that when she drew the well water, she would find a red blossom floating in the bucket. Slowly, Saeng walked down the narrow aisle toward the hibiscus. Orchids, lanna bushes, oleanders, elephant ear begonias, and bougainvillea vines surrounded her. Plants that she had not even realized she had known but had forgotten drew her back into her childhood world. When she got to the hibiscus, she reached out and touched a petal gently. It felt smooth and cool, with a hint of velvet toward the center—just as she had known it would feel. And beside it was yet another old friend, a small shrub with waxy leaves and dainty flowers with purplish petals and white centers. “Madagascar periwinkle,” its tag announced. How strange to see it in a pot, Saeng thought. Back home it just grew wild, jutting out from the cracks in brick walls or between tiled roofs. And that rich, sweet scent—that was familiar, too. Saeng scanned the greenery around her and found a tall, gangly plant with exquisite little white blossoms on it. “Dok Malik,” she said, savoring the feel of the word on her tongue, even as she silently noted the English name on its tag, “jasmine.” One of the blossoms had fallen off, and carefully Saeng picked it up and smelled it. She closed her eyes and breathed in, deeply. The familiar fragrance filled her lungs, and Saeng could almost feel the light strands of her grandmother’s long gray hair, freshly washed, as she combed it out with the fine-toothed buffalo-horn comb. And when the sun had dried it, Saeng would help the gnarled old fingers knot the hair into a bun, then slip a dok Malik bud into it. Saeng looked at the white bud in her hand now, small and fragile. Gently, she closed her palm around it and held it tight. That, at least, she could hold on to. But where was the fine-toothed comb? The hibiscus hedge? The well? Her gentle grandmother? A wave of loss so deep and strong that it stung Saeng’s eyes now swept over her. A blink, a channel switch, a boat ride into the night, and it was all gone. Irretrievably, irrevocably gone. And in the warm moist shelter of the greenhouse, Saeng broke down and wept. It was already dusk when Saeng reached home. The wind was blowing harder, tearing off the last remnants of green in the chicory weeds that were growing out of the cracks in the sidewalk. As if oblivious to the cold, her mother was still out in the vegetable garden, digging up the last of the onions with a rusty trowel. She did not see Saeng until the girl had quietly knelt down next to her. Her smile of welcome warmed Saeng. “Ghup ma laio le? You’re back?” she said cheerfully. “Goodness, it’s past five. What took you so long? How did it go? Did you—?” Then she noticed the potted plant that Saeng was holding, its leaves quivering in the wind. Mrs. Panouvong uttered a small cry of surprise and delight. “Dok faeng-noi!” she said. “Where did you get it?” “I bought it,” Saeng answered, dreading her mother’s next question. “How much?” For answer Saeng handed her mother some coins. “That’s all?” Mrs. Panouvong said, appalled, “Oh, but I forgot! You and the Lambert boy ate Bee-Maags . . . .” “No, we didn’t, Mother,” Saeng said. “Then what else—?” “Nothing else. I paid over nineteen dollars for it.” “You what?” Her mother stared at her incredulously. “But how could you? All the seeds for this vegetable garden didn’t cost that much! You know how much we—” She paused, as she noticed the tearstains on her daughter’s cheeks and her puffy eyes. “What happened?” she asked, more gently. “I—I failed the test,” Saeng said. For a long moment Mrs. Panouvong said nothing. Saeng did not dare look her mother in the eye. Instead, she stared at the hibiscus plant and nervously tore off a leaf, shredding it to bits. Her mother reached out and brushed the fragments of green off Saeng’s hands. “It’s a beautiful plant, this dok faeng-noi,” she finally said. “I’m glad you got it.” “It’s—it’s not a real one,” Saeng mumbled. “I mean, not like the kind we had at—at—” She found that she was still too shaky to say the words at home, lest she burst into tears again. “Not like the kind we had before,” she said. “I know,” her mother said quietly. “I’ve seen this kind blooming along the lake. Its flowers aren’t as pretty, but it’s strong enough to make it through the cold months here, this winter hibiscus. That’s what matters.” She tipped the pot and deftly eased the ball of soil out, balancing the rest of the plant in her other hand. “Look how root-bound it is, poor thing,” she said. “Let’s plant it, right now.” She went over to the corner of the vegetable patch and started to dig a hole in the ground. The soil was cold and hard, and she had trouble thrusting the shovel into it. Wisps of her gray hair trailed out in the breeze, and her slight frown deepened the wrinkles around her eyes. There was a frail, wiry beauty to her that touched Saeng deeply. “Here, let me help, Mother,” she offered, getting up and taking the shovel away from her. Mrs. Panouvong made no resistance. “I’ll bring in the hot peppers and bitter melons, then, and start dinner. How would you like an omelet with slices of the bitter melon?” “I’d love it,” Saeng said. Left alone in the garden, Saeng dug out a hole and carefully lowered the “winter hibiscus” into it. She could hear the sounds of cooking from the kitchen now, the beating of eggs against a bowl, the sizzle of hot oil in the pan. The pungent smell of bitter melon wafted out, and Saeng’s mouth watered. It was a cultivated taste, she had discovered—none of her classmates or friends, not even Mrs. Lambert, liked it—this sharp, bitter melon that left a golden aftertaste on the tongue. But she had grown up eating it and, she admitted to herself, much preferred it to a Big Mac. The “winter hibiscus” was in the ground now, and Saeng tamped down the soil around it. Overhead, a flock of Canada geese flew by, their faint honks clear and—yes—familiar to Saeng now. Almost reluctantly, she realized that many of the things that she had thought of as strange before had become, through the quiet repetition of season upon season, almost familiar to her now. Like the geese. She lifted her head and watched as their distinctive V was etched against the evening sky, slowly fading into the distance. When they come back, Saeng vowed silently to herself, in the spring, when the snows melt and the geese return and this hibiscus is budding, then I will take that test again. “Winter Hibiscus” by Minfong Ho, copyright © 1993 by Minfong Ho, from Join In, Multiethnic Short Stories, by Donald R. Gallo, ed. Instructions: Read the last paragraph of the source essay given earlier. \"When they come back, Saeng vowed silently to herself, in the spring, when the snows melt and the geese return and this hibiscus is budding, then I will take that test again.\" Write a response that explains why the author concludes the story with this paragraph. In your response, include details and examples from the story that support your ideas.',\n",
    "        \"Score Point 3: The response demonstrates an understanding of the complexities of the text. Addresses the demands of the question Uses expressed and implied information from the text Clarifies and extends understanding beyond the literal \\nScore 2: The response demonstrates a partial or literal understanding of the text. Addresses the demands of the question, although may not develop all parts equally Uses some expressed or implied information from the text to demonstrate understanding May not fully connect the support to a conclusion or assertion made about the text(s) \\nScore 1: The response shows evidence of a minimal understanding of the text. May show evidence that some meaning has been derived from the text May indicate a misreading of the text or the question May lack information or explanation to support an understanding of the text in relation to the question \\nScore Point 0: The response is completely irrelevant or incorrect, or there is no response.\",\n",
    "        \"0-3\"\n",
    "    ],\n",
    "    [\n",
    "        5,\n",
    "        8,\n",
    "        \"Source Essay: Narciso Rodriguez from Home: The Blueprints of Our Lives My parents, originally from Cuba, arrived in the United States in 1956. After living for a year in a furnished one-room apartment, twenty-one-year-old Rawedia Maria and twenty-seven-year-old Narciso Rodriguez, Sr., could afford to move into a modest, three-room apartment I would soon call home. In 1961, I was born into this simple house, situated in a two-family, blond-brick building in the Ironbound section of Newark, New Jersey. Within its walls, my young parents created our traditional Cuban home, the very heart of which was the kitchen. My parents both shared cooking duties and unwittingly passed on to me their rich culinary skills and a love of cooking that is still with me today (and for which I am eternally grateful). Passionate Cuban music (which I adore to this day) filled the air, mixing with the aromas of the kitchen. Here, the innocence of childhood, the congregation of family and friends, and endless celebrations that encompassed both, formed the backdrop to life in our warm home. Growing up in this environment instilled in me a great sense that “family” had nothing to do with being a blood relative. Quite the contrary, our neighborhood was made up of mostly Spanish, Cuban, and Italian immigrants at a time when overt racism was the norm and segregation prevailed in the United States. In our neighborhood, despite customs elsewhere, all of these cultures came together in great solidarity and friendship. It was a close-knit community of honest, hardworking immigrants who extended a hand to people who, while not necessarily their own kind, were clearly in need. Our landlord and his daughter, Alegria (my babysitter and first friend), lived above us, and Alegria graced our kitchen table for meals more often than not. Also at the table were Sergio and Edelmira, my surrogate grandparents who lived in the basement apartment. (I would not know my “real” grandparents, Narciso the Elder and Consuelo, until 1970 when they were allowed to leave Cuba.) My aunts Bertha and Juanita and my cousins Arnold, Maria, and Rosemary also all lived nearby and regularly joined us at our table. Countless extended family members came and went — and there was often someone staying with us temporarily until they were able to get back on their feet. My parents always kept their arms and their door open to the many people we considered family, knowing that they would do the same for us. My mother and father had come to this country with such courage, without any knowledge of the language or the culture. They came selflessly, as many immigrants do, to give their children a better life, even though it meant leaving behind their families, friends, and careers in the country they loved. They struggled both personally and financially, braving the harsh northern winters while yearning for their native tropics and facing cultural hardships. The barriers to work were strong and high, and my parents both had to accept that they might not be able to find the kind of jobs they deserved. In Cuba, Narciso, Sr., had worked in a laboratory and Rawedia Maria had studied chemical engineering. In the United States, they had to start their lives over entirely, taking whatever work they could find. The faith that this struggle would lead them and their children to better times drove them to endure these hard times. I will always be grateful to my parents for their love and sacrifice. I’ve often told them that what they did was a much more courageous thing than I could have ever done. I’ve often told them of my admiration for their strength and perseverance, and I’ve thanked them repeatedly. But, in reality, there is no way to express my gratitude for the spirit of generosity impressed upon me at such an early age and the demonstration of how important family and friends are. These are two lessons that my parents did not just tell me. They showed me with their lives, and these teachings have been the basis of my life. It was in this simple house that my parents welcomed other refugees to celebrate their arrival to this country and where I celebrated my first birthdays. It was in the warmth of the kitchen in this humble house where a Cuban feast (albeit a frugal Cuban feast) always filled the air with not just scent and music but life and love. It was here where I learned the real definition of “family.” And for this, I will never forget that house or its gracious neighborhood or the many things I learned there about how to love. I will never forget how my parents turned this simple house into a home. — Narciso Rodriguez, Fashion designer Hometown: Newark, New Jersey “Narciso Rodriguez” by Narciso Rodriguez, from Home: The Blueprints of Our Lives. Copyright © 2006 by John Edwards. Instructions: Describe the mood created by the author in the memoir. Support your answer with relevant and specific information from the memoir.\",\n",
    "        \"Score Point 4: The response is a clear, complete, and accurate description of the mood created by the author. The response includes relevant and specific information from the memoir. \\nScore Point 3: The response is a mostly clear, complete, and accurate description of the mood created by the author. The response includes relevant but often general information from the memoir. \\nScore Point 2: The response is a partial description of the mood created by the author. The response includes limited information from the memoir and may include misinterpretations. \\nScore Point 1: The response is a minimal description of the mood created by the author. The response includes little or no information from the memoir and may include misinterpretations. OR The response relates minimally to the task. \\nScore Point 0: The response is incorrect or irrelevant or contains insufficient information to demonstrate comprehension.\",\n",
    "        \"0-4\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "essay_rubric_df = pd.DataFrame(data=data, columns=columns)\n",
    "essay_rubric_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8a0b1-4fb1-4e27-93d9-8b3a1550d4f4",
   "metadata": {},
   "source": [
    "### Model Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "674e439e-0137-4a35-8f79-e0e7f3327997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_essay_eval_prompt(current_rubric, essay):\n",
    "    prompt = \"You are tasked to grade an essay written by a grade <grade_level> student given a set of rubrics, an essay prompt, and a range of possible scores to give. These are as follows:\\n\\nEssay prompt:\\n<prompt>\\n\\nRubrics:\\n<rubrics>\\n\\nEssay:\\n<submission>\\n\\nDesired Output:\\nOutput a single numerical grade between the range of <score_range>, inclusive, to grade this essay. In addition, give a brief explanation for the given grade (<400 words). Output this in the following format:\\nScore: <score>\\nExplanation: <explanation>\"\n",
    "    \n",
    "    prompt = prompt.replace(\"<grade_level>\", str(current_rubric.grade_level))\n",
    "    prompt = prompt.replace(\"<prompt>\", current_rubric.prompt)\n",
    "    prompt = prompt.replace(\"<rubrics>\", current_rubric.rubrics)\n",
    "    prompt = prompt.replace(\"<submission>\", essay)\n",
    "    prompt = prompt.replace(\"<score_range>\", current_rubric.score_range)\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "399517e8-d38f-4b08-873d-7d5ac07b5596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are tasked to grade an essay written by a grade 8 student given a set of rubrics, an essay prompt, and a range of possible scores to give. These are as follows:\n",
      "\n",
      "Essay prompt:\n",
      "More and more people use computers, but not everyone agrees that this benefits society. Those who support advances in technology believe that computers have a positive effect on people. They teach hand-eye coordination, give people the ability to learn about faraway places and people, and even allow people to talk online with other people. Others have different ideas. Some experts are concerned that people are spending too much time on their computers and less time exercising, enjoying nature, and interacting with family and friends. Write a letter to your local newspaper in which you state your opinion on the effects computers have on people. Persuade the readers to agree with you.\n",
      "\n",
      "Rubrics:\n",
      "Score Point 1: An undeveloped response that may take a position but offers no more than very minimal support. Typical elements: Contains few or vague details. Is awkward and fragmented. May be difficult to read and understand. May show no awareness of audience.\n",
      "Score Point 2: An under-developed response that may or may not take a position. Typical elements: Contains only general reasons with unelaborated and/or list-like details. Shows little or no evidence of organization. May be awkward and confused or simplistic. May show little awareness of audience. \n",
      "Score Point 3: A minimally-developed response that may take a position, but with inadequate support and details. Typical elements: Has reasons with minimal elaboration and more general than specific details. Shows some organization. May be awkward in parts with few transitions. Shows some awareness of audience. \n",
      "Score Point 4: A somewhat-developed response that takes a position and provides adequate support. Typical elements: Has adequately elaborated reasons with a mix of general and specific details. Shows satisfactory organization. May be somewhat fluent with some transitional language. Shows adequate awareness of audience. \n",
      "Score Point 5: A developed response that takes a clear position and provides reasonably persuasive support. Typical elements: Has moderately well elaborated reasons with mostly specific details. Exhibits generally strong organization. May be moderately fluent with transitional language throughout. May show a consistent awareness of audience. \n",
      "Score Point 6: A well-developed response that takes a clear and thoughtful position and provides persuasive support. Typical elements: Has fully elaborated reasons with specific details. Exhibits strong organization. Is fluent and uses sophisticated transitional language. May show a heightened awareness of audience.\n",
      "\n",
      "Essay:\n",
      "Is everyone freaking out about computers for no reason? Computers are awesome! They're like having a superhero sidekick in your pocket. They can teach you anything you want to know, from how to build a volcano (for science class, of course!) to what life is like on the other side of the world. Plus, games help your hand-eye coordination, which is basically a superpower for gamers like me.\n",
      "\n",
      "Sure, maybe some grown-ups spend too much time staring at screens, but that's their problem, not ours. We can totally use computers for good stuff and still hang out with friends or play outside.  So, lighten up everyone, computers are here to stay, and they're making our lives way cooler!\n",
      "\n",
      "Your friend,\n",
      "\n",
      "Gamer Girl extraordinaire\n",
      "\n",
      "Desired Output:\n",
      "Output a single numerical grade between the range of 1-6, inclusive, to grade this essay. In addition, give a brief explanation for the given grade (<400 words). Output this in the following format:\n",
      "Score: <score>\n",
      "Explanation: <explanation>\n"
     ]
    }
   ],
   "source": [
    "# Test prompt generation\n",
    "test_essay = \"Is everyone freaking out about computers for no reason? Computers are awesome! They're like having a superhero sidekick in your pocket. They can teach you anything you want to know, from how to build a volcano (for science class, of course!) to what life is like on the other side of the world. Plus, games help your hand-eye coordination, which is basically a superpower for gamers like me.\\n\\nSure, maybe some grown-ups spend too much time staring at screens, but that's their problem, not ours. We can totally use computers for good stuff and still hang out with friends or play outside.  So, lighten up everyone, computers are here to stay, and they're making our lives way cooler!\\n\\nYour friend,\\n\\nGamer Girl extraordinaire\"\n",
    "test_prompt = create_essay_eval_prompt(essay_rubric_df[essay_rubric_df.essay_set == 1].T.iloc[:,0], test_essay)\n",
    "print(test_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae843472-d2cf-4f2a-88d9-09a74c8d3b5d",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf3d20af-1e3a-4c2d-aca5-e117219e1919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essay_eval(essay_set, essay):\n",
    "    current_rubric = essay_rubric_df[essay_rubric_df.essay_set == essay_set].T.iloc[:,0]\n",
    "    essay_train_prompt = create_essay_eval_prompt(current_rubric, essay)\n",
    "    input_tokens = tokenizer(essay_train_prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad(): # Tells PyTorch not to train the model on your input\n",
    "        output_tokens = model.generate(input_tokens [\"input_ids\"], num_return_sequences=1, max_length=1050)\n",
    "\n",
    "    output = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "300f48d7-1305-4e4d-bf69-6d3e2ebed7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m essay_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m essay_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mget_essay_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43messay_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43messay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore: \u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28meval\u001b[39m\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      7\u001b[0m     explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m[(\u001b[38;5;28meval\u001b[39m\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExplanation: \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExplanation: \u001b[39m\u001b[38;5;124m'\u001b[39m)):]\n",
      "Cell \u001b[1;32mIn[36], line 7\u001b[0m, in \u001b[0;36mget_essay_eval\u001b[1;34m(essay_set, essay)\u001b[0m\n\u001b[0;32m      4\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m tokenizer(essay_train_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(): \u001b[38;5;66;03m# Tells PyTorch not to train the model on your input\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     output_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1050\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_tokens[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1995\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1997\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1998\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1315\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1028\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1027\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwte(input_ids)\n\u001b[1;32m-> 1028\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;66;03m# Attention mask.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "essay_results_df = pd.DataFrame()\n",
    "\n",
    "for index, row in essay_df.iterrows():\n",
    "    eval = get_essay_eval(row.essay_set, row.essay)\n",
    "\n",
    "    score = eval[len('Score: '): eval.find('\\n')]\n",
    "    explanation = eval[(eval.find('Explanation: ') + len('Explanation: ')):]\n",
    "\n",
    "    result = {'essay_id': row.essay_id,\n",
    "              'model_score': int(score),\n",
    "              'explanation': explanation,\n",
    "              'ground_truth_score': row.rater1_domain1}\n",
    "\n",
    "    essay_results_df = pd.concat([essay_results_df, pd.DataFrame([result])], ignore_index=True)\n",
    "    print(f'Evaluating essay {index+1}/{len(essay_df)}')\n",
    "\n",
    "    # for testing\n",
    "    if (index == 2):\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278db232-56cb-46a2-850b-8cfcc460d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3f5c5-6b34-462d-b55e-aea223efe39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210f385-ed43-491d-93d2-730418fd590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_qwk = cohen_kappa_score(essay_results_df.model_score, essay_results_df.ground_truth_score)\n",
    "print(f\"QWK score for essay autograding: {essay_qwk}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
